создай библиотеку на python которая:
- устанавливается как скрипт в систему
- принимает последовательность параметров
- обрабатывает последовательность параметров и получает строку и артефакты запроса.
- на основе этого запроса делает запрос в api провайдера - llm (может поддерживать разные провайдеры: claude chatgpt deepseek) claude по умолчанию.

сформируй документацию для репозитория, документацию по использованию и unit тесты на компоненты.

Для обработки входящих аргументов:
Последовательность параметров склеивает как строку разделенную пробелами
- если слово (параметр) является путем до существующего файла:
-- если он текстовый то его содержимое поддкладывает в результирующую строку, отдедленными переносами строки и заголовками например ### ./file.py ###
-- если он бинарный добавить его в hex виде аналогично снабдив заголовком
-- при достаточно большом файле запрашивает подтверждение (для каждого большого файла)
-- для бинарных файлов предложи вставить целиком или сократить.
-- для сокращенного бинарного файла сократи вывод в результирующей строке `hex bytes start`...{total file bytes len}...`hex bytes end`
- если текст начинается с кавычки то считается параметром до следующей закрывающей кавычки " ' если кавычка не предворяется escape символом \
- содержимое в кавычкаах считается одним словом
- если слово является параметром -i то перед запросом выведи итоговый получившийся запрос с запросом подтверждения.
- провайдер задается с помощью параметра (один аргумент / одно слово) --llm={provider}
- если провайдер (задается парметром для класса обработчика) умеет работать с файлами то не вставляй файлы в запрос а организуй структуру с перечнем подгруженных файлов для создания запроса.
- из всех переданным пользователем параметров сформируй структуру с результиирующим текстом запроса, параметрами вывода и интерактивности, прикладываемыми файлами и их путями и режимами включения (полный/неполный/включен в текст или ьбудет передан файлом) информацию о провайдере и другую необходимую информацию,
- если слово-аргумент является параметром --dry-run просто выведи соддержимое запроса (текст и после него отфарматированную сиистемную информацию о запросе)

организуй это в модуле что бы его можно было независимо протестировать unit-ами: для входящих аргументов результирующую структуру запроса для дальнейшего ее использования для запроса llm.

напиши unit тесты на вышеуказанные кейсы и возможные вариации и корнеркейсы.

Запрос к llm:
Для каждого из провайдеров сформируй клиенты - отдельный класс.
Для доступа к api LLM возьми ключи из ENV или файла конфигурации из корневой директории пользователя (создай конфиг по умолчанию при установке пакета)
Входням для клиента является структура полученная после парсинга результата.
Выбор провайдера происходит в зависимости от результата парсинга запроса (в структуре запроса поле провайдера)
При выборе провайдера для которого не достаточно credentials прерви работу с вывродом ошибоки.

Результат запроса от api llm выводится в stdout в качестве ответа.
Предусмотри как интерактивный режим - как только часть ответа будет доступна, то сразу же вывести ее пользователю.